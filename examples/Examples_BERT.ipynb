{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsp8kFR8e5jH4LEsVMZ9XW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalmysore/AI/blob/main/Examples_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Gpj8I5jAgehj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhPENWtXgdYi"
      },
      "outputs": [],
      "source": [
        "#Example of how to connect to BERT and perform sentiment analysis\n",
        "# Replace 'textattack/bert-base-uncased-SST-2' with the model name you want to use\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load pre-trained sentiment analysis model and tokenizer\n",
        "model_name = \"textattack/bert-base-uncased-SST-2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Example sentences for sentiment analysis\n",
        "sentences = [\n",
        "    \"I love this recipe, it's amazing!\",\n",
        "    \"The food was great and very tasty.\",\n",
        "    \"This food was disappointing, I didn't enjoy it.\",\n",
        "]\n",
        "\n",
        "# Tokenize and get model predictions\n",
        "for sentence in sentences:\n",
        "    # Tokenize input sentence\n",
        "    tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Forward pass through the model\n",
        "    outputs = model(**tokens)\n",
        "\n",
        "    # Get predicted sentiment (positive or negative)\n",
        "    prediction = \"positive\" if outputs.logits.argmax().item() == 1 else \"negative\"\n",
        "\n",
        "    # Print the result\n",
        "    print(f\"Sentence: '{sentence}'\\nPredicted Sentiment: {prediction}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Pipeline for Question and answering\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the question-answering pipeline with a pre-trained BERT model\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\")\n",
        "\n",
        "# Ask a question\n",
        "question = \"What food is non spicy?\"\n",
        "context = \"Sometimes its better to eat non spicy foods like plain rice and plain yoghurt this will help you stay alert and focused, once in a while eating spicy food is not a bad option either\"\n",
        "\n",
        "# Get the answer\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "\n",
        "# Print the answer\n",
        "print(\"Answer:\", answer[\"answer\"])"
      ],
      "metadata": {
        "id": "O8NcCDNHg_3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "ci-3bj9nkGhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uses BertForQuestionAnswering for quries , you need to install torch from above command\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(\"What food is non spicy?\", \"Sometimes its better to eat non spicy foods like plain rice and plain yoghurt this will help you stay alert and focused, once in a while eating spicy food is not a bad option either.\", return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass through the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the start and end logits\n",
        "start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "# Get the answer span\n",
        "answer_start = torch.argmax(start_logits)\n",
        "answer_end = torch.argmax(end_logits) + 1\n",
        "answer = tokenizer.decode(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "\n",
        "# Print the answer\n",
        "print(\"Answer:\", answer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jCSp1LJ5jCyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "weight_path = \"kaporter/bert-base-uncased-finetuned-squad\"\n",
        "# loading tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(weight_path)\n",
        "#loading the model\n",
        "model = BertForQuestionAnswering.from_pretrained(weight_path)\n",
        "question = \"How many cuisines does the Indian food have ?\"\n",
        "context = \"Indian cuisine consists of a variety of regional and traditional cuisines native to India. Given the diversity in soil, climate, culture, ethnic groups, and occupations, these cuisines vary substantially and use locally available spices, herbs, vegetables, and fruits. There are 100050 varieties of Indian cusine\"\n",
        "\n",
        "input_ids = tokenizer.encode(question, context)\n",
        "print (f'We have about {len(input_ids)} tokens generated')\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "out = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                token_type_ids=torch.tensor([token_type_ids]))\n",
        "\n",
        "start_logits,end_logits = out['start_logits'],out['end_logits']\n",
        "# Find the tokens with the highest `start` and `end` scores.\n",
        "answer_start = torch.argmax(start_logits)\n",
        "answer_end = torch.argmax(end_logits)\n",
        "\n",
        "ans = ''.join(tokens[answer_start:answer_end])\n",
        "print('Predicted answer:', ans)\n"
      ],
      "metadata": {
        "id": "WXqyCugzlcqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO88NIVtZRkoNmYkiDDRzzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalmysore/AI/blob/main/examples/modelwar/Modelwars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyHDp9jm83Ku",
        "outputId": "79e8fb3f-0db0-4afc-ec96-e7e45c090480"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "WbDREDtG8pez",
        "outputId": "51192000-bf4c-4e8a-903d-d6fb39e7f5ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All Flax model weights were used when initializing GPTNeoForCausalLM.\n",
            "\n",
            "Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "All Flax model weights were used when initializing GPTNeoForCausalLM.\n",
            "\n",
            "Some weights of GPTNeoForCausalLM were not initialized from the Flax model and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "  |   |  \n",
            "---------\n",
            "Player 1's turn (X)\n",
            "The current Tic Tac Toe board is: , , , , , , , , . Your move?  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 32, but `max_length` is set to 2. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'The current Tic Tac Toe board is: , , , , , , , , . Your move?  '",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0e05f6112786>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-0e05f6112786>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(model1, model2)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Player 1's turn (X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Player 2's turn (O)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0e05f6112786>\u001b[0m in \u001b[0;36mget_model_move\u001b[0;34m(model, tokenizer, board)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'The current Tic Tac Toe board is: , , , , , , , , . Your move?  '"
          ]
        }
      ],
      "source": [
        "from transformers import GPTNeoForCausalLM, AutoTokenizer,AutoModel\n",
        "import torch\n",
        "def print_board(board):\n",
        "    for row in board:\n",
        "        print(\" | \".join(row))\n",
        "        print(\"---------\")\n",
        "\n",
        "def check_winner(board):\n",
        "    # Check rows\n",
        "    for row in board:\n",
        "        if all(cell == 'X' for cell in row) or all(cell == 'O' for cell in row):\n",
        "            return True\n",
        "\n",
        "    # Check columns\n",
        "    for col in range(3):\n",
        "        if all(board[row][col] == 'X' for row in range(3)) or all(board[row][col] == 'O' for row in range(3)):\n",
        "            return True\n",
        "\n",
        "    # Check diagonals\n",
        "    if all(board[i][i] == 'X' for i in range(3)) or all(board[i][2 - i] == 'O' for i in range(3)):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def is_board_full(board):\n",
        "    return all(all(cell != ' ' for cell in row) for row in board)\n",
        "\n",
        "def play_game(model1, model2):\n",
        "    player1 = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m', from_flax=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m', use_fast=True)\n",
        "    player2 = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m', from_flax=True)\n",
        "\n",
        "    board = [[' ' for _ in range(3)] for _ in range(3)]\n",
        "    current_player = 'X'\n",
        "\n",
        "    while True:\n",
        "        print_board(board)\n",
        "\n",
        "        if current_player == 'X':\n",
        "            print(\"Player 1's turn (X)\")\n",
        "            move = get_model_move(player1, tokenizer, board)\n",
        "        else:\n",
        "            print(\"Player 2's turn (O)\")\n",
        "            move = get_model_move(player2, tokenizer, board)\n",
        "\n",
        "        row, col = move // 3, move % 3\n",
        "\n",
        "        if board[row][col] == ' ':\n",
        "            board[row][col] = current_player\n",
        "            if check_winner(board):\n",
        "                print_board(board)\n",
        "                print(f\"Player {current_player} wins!\")\n",
        "                break\n",
        "            elif is_board_full(board):\n",
        "                print_board(board)\n",
        "                print(\"It's a tie!\")\n",
        "                break\n",
        "            else:\n",
        "                current_player = 'O' if current_player == 'X' else 'X'\n",
        "        else:\n",
        "            print(\"Invalid move. Try again.\")\n",
        "\n",
        "def get_model_move(model, tokenizer, board):\n",
        "    flat_board = [cell for row in board for cell in row]\n",
        "    input_text = f\"The current Tic Tac Toe board is: {', '.join(flat_board)}. Your move? \"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_length=2)\n",
        "        print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "        move = int(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "\n",
        "    return move\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model1 = \"gpt2\"\n",
        "    model2 = \"gpt2\"\n",
        "\n",
        "    play_game(model1, model2)\n"
      ]
    }
  ]
}